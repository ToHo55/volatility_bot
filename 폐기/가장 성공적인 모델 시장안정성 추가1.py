# RSI ì—­ì¶”ì„¸ ì „ëµ ìë™ ë°±í…ŒìŠ¤íŠ¸ (ë‹¤ì¤‘ ì•ŒíŠ¸ì½”ì¸)
# ì£¼ìš” êµ¬ì„±: ì „ëµ í´ë˜ìŠ¤ + ë‹¤ì¤‘ í‹°ì»¤ ë£¨í”„ + ì„±ê³¼ ë¹„êµ ë¶„ì„

import os
import time
import logging
import pyupbit
import pandas as pd
import numpy as np
import random  # random ëª¨ë“ˆ ì„í¬íŠ¸
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import multiprocessing as mp
from pathlib import Path
import pickle
import hashlib
from concurrent.futures import ProcessPoolExecutor, as_completed
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
log_level = logging.INFO # ë¡œê·¸ ë ˆë²¨ ì„¤ì • (DEBUG, INFO, WARNING, ERROR, CRITICAL)
log_format = '%(asctime)s [%(levelname)s] %(processName)s:%(threadName)s - %(message)s'
date_format = '%Y-%m-%d %H:%M:%S'

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
LOG_DIR = BASE_DIR / "logs"
CACHE_DIR = BASE_DIR / "cache"

# ë””ë ‰í† ë¦¬ ìƒì„±
try:
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    log_file_path = LOG_DIR / f"trading_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    print(f"ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_file_path}") # ê²½ë¡œ í™•ì¸ìš© ì¶œë ¥
except Exception as e:
    print(f"[ERROR] ë””ë ‰í† ë¦¬ ìƒì„± ë˜ëŠ” ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    # ëŒ€ì²´ ê²½ë¡œ ì‚¬ìš© (ì‚¬ìš©ì í™ˆ ë””ë ‰í† ë¦¬)
    user_home = Path.home()
    LOG_DIR = user_home / "volatility_bot_logs"
    CACHE_DIR = user_home / "volatility_bot_cache"
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    log_file_path = LOG_DIR / f"trading_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    print(f"ëŒ€ì²´ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_file_path}")

# ë¡œê±° ì„¤ì •
logger = logging.getLogger()
logger.setLevel(log_level)

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì„ íƒì : í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©)
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# í¬ë§·í„° ìƒì„±
formatter = logging.Formatter(log_format, datefmt=date_format)

# ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ (ì½˜ì†” ì¶œë ¥)
console_handler = logging.StreamHandler()
console_handler.setLevel(log_level)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# íŒŒì¼ í•¸ë“¤ëŸ¬ (íŒŒì¼ ì¶œë ¥)
try:
    file_handler = logging.FileHandler(log_file_path, encoding='utf-8')
    file_handler.setLevel(log_level) # íŒŒì¼ í•¸ë“¤ëŸ¬ ë ˆë²¨ ëª…ì‹œì  ì„¤ì •
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    logger.info("ë¡œê¹… ì„¤ì • ì™„ë£Œ. ì½˜ì†” ë° íŒŒì¼ ë¡œê¹… ì‹œì‘.")
except Exception as e:
    print(f"[ERROR] íŒŒì¼ í•¸ë“¤ëŸ¬ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    logger.error(f"íŒŒì¼ í•¸ë“¤ëŸ¬ ì„¤ì • ì‹¤íŒ¨: {e}", exc_info=True)

# ë””ë²„ê·¸ ë¡œê¹… ë¹„í™œì„±í™” (ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬)
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('asyncio').setLevel(logging.WARNING)

def check_ticker_validity(ticker: str) -> bool:
    """í‹°ì»¤ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    try:
        # í˜„ì¬ê°€ ì¡°íšŒë¡œ ìœ íš¨ì„± ì²´í¬
        current_price = pyupbit.get_current_price(ticker)
        return current_price is not None
    except Exception as e:
        logging.error(f"í‹°ì»¤ ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨ ({ticker}): {str(e)}")
        return False

def safe_request_with_retry(func, *args, max_retries: int = 5, delay: float = 1.0, **kwargs) -> Optional[pd.DataFrame]:
    """ì•ˆì „í•œ API ìš”ì²­ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    for attempt in range(max_retries):
        try:
            result = func(*args, **kwargs)
            if result is not None:
                return result
        except Exception as e:
            logging.warning(f"ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
        
        # ì§€ìˆ˜ ë°±ì˜¤í”„
        time.sleep(delay * (2 ** attempt))
    return None

class RSIReversalStrategy:
    def __init__(self, ticker: str, is_backtest: bool = False):
        self.ticker = ticker
        self.is_backtest = is_backtest
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°
        self.rsi_period = 14
        self.bb_period = 20
        self.bb_std = 2.0
        self.ma_short = 10  # ë‹¨ê¸° ì´ë™í‰ê· 
        self.ma_long = 30   # ì¥ê¸° ì´ë™í‰ê· 
        self.vol_window = 20  # ë³€ë™ì„± ê³„ì‚° ê¸°ê°„
        
        # ì†ìµ ê´€ë ¨ íŒŒë¼ë¯¸í„°
        self.take_profit = 0.08     # 8%ë¡œ ìƒí–¥ ì¡°ì •
        self.stop_loss = -0.04      # -4%ë¡œ í•˜í–¥ ì¡°ì •
        self.trailing_stop = 0.03   # 3%ë¡œ ìƒí–¥ ì¡°ì •
        self.max_hold_time = 96     # ìµœëŒ€ ë³´ìœ  ì‹œê°„ 4ì¼ë¡œ í™•ëŒ€
        
        # ëœë¤í™” ë²”ìœ„ ì¡°ì •
        if self.is_backtest:
            self.rsi_period = random.randint(12, 16)
            self.bb_period = random.randint(18, 22)
            self.bb_std = random.uniform(1.8, 2.2)
            self.ma_short = random.randint(8, 12)
            self.ma_long = random.randint(28, 32)
            
            # ì†ìµ íŒŒë¼ë¯¸í„° ëœë¤í™” (ë” ë„“ì€ ë²”ìœ„)
            self.take_profit = random.uniform(0.06, 0.10)
            self.stop_loss = random.uniform(-0.05, -0.03)
            self.trailing_stop = random.uniform(0.02, 0.04)
        
        # ê±°ë˜ ê¸°ë¡
        self.trade_history = []
        self.last_trade_time = None
        
    def calculate_trend_strength(self, df: pd.DataFrame) -> float:
        """ì¶”ì„¸ ê°•ë„ ê³„ì‚°"""
        close_prices = df['close'].astype(float)
        ma_short = close_prices.rolling(window=self.ma_short).mean()
        ma_long = close_prices.rolling(window=self.ma_long).mean()
        
        # ì¶”ì„¸ ê°•ë„ ê³„ì‚° (ë‹¨ê¸°/ì¥ê¸° ì´í‰ì„  ë¹„ìœ¨)
        trend_strength = (ma_short.iloc[-1] / ma_long.iloc[-1] - 1) * 100
        return float(trend_strength)

    def calculate_volatility(self, df: pd.DataFrame) -> Tuple[float, float]:
        """ë³€ë™ì„± ê³„ì‚°"""
        high_prices = df['high'].astype(float)
        low_prices = df['low'].astype(float)
        
        # ì¼ì¤‘ ë³€ë™ì„±
        daily_volatility = ((high_prices / low_prices - 1) * 100).rolling(window=self.vol_window).mean()
        
        # ATR ìŠ¤íƒ€ì¼ ë³€ë™ì„±
        tr = pd.DataFrame(index=df.index)
        tr['hl'] = high_prices - low_prices
        tr['hc'] = abs(high_prices - df['close'].shift(1))
        tr['lc'] = abs(low_prices - df['close'].shift(1))
        atr = tr.max(axis=1).rolling(window=self.vol_window).mean()
        
        return float(daily_volatility.iloc[-1]), float(atr.iloc[-1])

    def evaluate_entry(self, df: pd.DataFrame) -> bool:
        """ì§„ì… ì¡°ê±´ì„ ì ìˆ˜í™”í•˜ì—¬ í‰ê°€ (ë” ì—„ê²©í•œ ì¡°ê±´)"""
        if len(df) < max(self.rsi_period, self.bb_period, self.ma_long) + 10:
            return False
        
        score = 0
        current_price = float(df['close'].iloc[-1])
        
        # RSI ì¡°ê±´ (0-3ì )
        rsi = self.calculate_rsi(df)
        current_rsi = float(rsi.iloc[-1])
        if current_rsi < 25:  # ë” ë‚®ì€ RSI ê¸°ì¤€
            score += 3
        elif current_rsi < 30:
            score += 2
        elif current_rsi < 35:
            score += 1
        
        # RSI í•˜ë½ ì¶”ì„¸ í™•ì¸
        rsi_values = rsi.iloc[-3:]
        if all(rsi_values.iloc[i] > rsi_values.iloc[i+1] for i in range(len(rsi_values)-1)):
            score += 2  # ì—°ì† í•˜ë½ì‹œ ì¶”ê°€ ì ìˆ˜
        
        # ë³¼ë¦°ì € ë°´ë“œ ì¡°ê±´ (0-3ì )
        bb_lower, bb_middle, bb_upper = self.calculate_bollinger_bands(df)
        bb_lower_val = float(bb_lower.iloc[-1])
        bb_middle_val = float(bb_middle.iloc[-1])
        
        if current_price < bb_lower_val:
            score += 3
        elif current_price < (bb_lower_val + bb_middle_val) / 2:
            score += 1
        
        # ê±°ë˜ëŸ‰ ì¡°ê±´ (0-3ì )
        volume_ma = df['volume'].rolling(window=20).mean()
        current_volume = float(df['volume'].iloc[-1])
        volume_ma_val = float(volume_ma.iloc[-1])
        
        if current_volume > volume_ma_val * 2.0:  # ê±°ë˜ëŸ‰ ê¸‰ì¦
            score += 3
        elif current_volume > volume_ma_val * 1.5:
            score += 2
        elif current_volume > volume_ma_val * 1.2:
            score += 1
        
        # ì¶”ì„¸ ê°•ë„ ì²´í¬ (-2~2ì )
        trend_strength = self.calculate_trend_strength(df)
        if trend_strength < -2.0:  # ê°•í•œ í•˜ë½ ì¶”ì„¸
            score += 2
        elif trend_strength < -1.0:  # ì•½í•œ í•˜ë½ ì¶”ì„¸
            score += 1
        elif trend_strength > 1.0:  # ìƒìŠ¹ ì¶”ì„¸ì—ì„œëŠ” ì§„ì… ì œí•œ
            score -= 2
        
        # ë³€ë™ì„± í•„í„°
        daily_vol, atr = self.calculate_volatility(df)
        if daily_vol > 5.0 or atr > 0.05:  # ë³€ë™ì„±ì´ ë„ˆë¬´ ë†’ìœ¼ë©´ ì§„ì… ì œí•œ
            score -= 2
        
        # ì¶”ê°€ í•„í„°
        if self.last_trade_time and (df.index[-1] - self.last_trade_time).total_seconds() < 14400:  # 4ì‹œê°„ìœ¼ë¡œ í™•ëŒ€
            return False
        
        # ìµœì†Œ 8ì  ì´ìƒ íšë“ì‹œ ì§„ì… (ë” ë†’ì€ ê¸°ì¤€)
        return score >= 8
        
    def evaluate_exit(self, df: pd.DataFrame, entry_price: float, hold_time: float) -> Tuple[bool, str]:
        """í‡´ì¶œ ì¡°ê±´ì„ ì ìˆ˜í™”í•˜ì—¬ í‰ê°€"""
        try:
            if len(df) < max(self.rsi_period, self.bb_period) + 10:
                return False, ""
            
            current_price = float(df['close'].iloc[-1])
            entry_price = float(entry_price)  # ëª…ì‹œì ìœ¼ë¡œ floatë¡œ ë³€í™˜
            profit_ratio = (current_price / entry_price) - 1.0
            
            # ì†ì ˆ/ì´ìµì‹¤í˜„
            if profit_ratio <= self.stop_loss:
                return True, "ì†ì ˆ"
            if profit_ratio >= self.take_profit:
                return True, "ì´ìµì‹¤í˜„"
            
            score = 0
            
            # RSI ì¡°ê±´ (0-2ì )
            rsi = self.calculate_rsi(df)
            current_rsi = float(rsi.iloc[-1])
            if current_rsi > 65:  # ê³¼ë§¤ìˆ˜
                score += 2
            elif current_rsi > 60:  # ì•½í•œ ê³¼ë§¤ìˆ˜
                score += 1
            
            # ë³¼ë¦°ì € ë°´ë“œ ì¡°ê±´ (0-2ì )
            lower, middle, upper = self.calculate_bollinger_bands(df)
            current_price = float(df['close'].iloc[-1])
            bb_upper = float(upper.iloc[-1])
            bb_middle = float(middle.iloc[-1])
            
            if current_price > bb_upper:  # ìƒë‹¨ ë°´ë“œ ìœ„
                score += 2
            elif current_price > (bb_upper + bb_middle) / 2:  # ìƒë‹¨ê³¼ ì¤‘ê°„ ì‚¬ì´
                score += 1
            
            # ë³´ìœ  ì‹œê°„ ê°€ì¤‘ì¹˜
            if hold_time >= self.max_hold_time * 0.8:  # ìµœëŒ€ ë³´ìœ  ì‹œê°„ì˜ 80% ì´ìƒ
                score += 2
            
            # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘
            if profit_ratio > self.take_profit * 0.5:
                high_since_entry = float(df['high'].max())  # ì „ì²´ ìµœê³ ê°€ ì‚¬ìš©
                trailing_ratio = (current_price / high_since_entry) - 1.0
                if trailing_ratio <= -self.trailing_stop:
                    return True, "íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘"
                
            # ìµœì†Œ 3ì  ì´ìƒ íšë“ì‹œ í‡´ì¶œ
            if score >= 3:
                return True, "ì¡°ê±´ ì¶©ì¡±"
            
            return False, ""
        
        except Exception as e:
            logging.error(f"í‡´ì¶œ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False, ""

    def calculate_rsi(self, df: pd.DataFrame) -> pd.Series:
        """RSI ê³„ì‚° ì‹œ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë¬¸ì œ ë°©ì§€"""
        # ë°ì´í„° íƒ€ì…ì„ floatìœ¼ë¡œ ë³€í™˜
        close_prices = df['close'].astype(float)
        delta = close_prices.diff()
        
        # ìƒìŠ¹í­ê³¼ í•˜ë½í­ ê³„ì‚°
        gain = delta.where(delta > 0, 0.0)
        loss = -delta.where(delta < 0, 0.0)
        
        # í‰ê·  ê³„ì‚°
        avg_gain = gain.rolling(window=self.rsi_period).mean()
        avg_loss = loss.rolling(window=self.rsi_period).mean()
        
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€
        avg_loss = avg_loss.replace(0, float('inf'))
        rs = avg_gain / avg_loss
        
        # RSI ê³„ì‚°
        rsi = 100 - (100 / (1 + rs))
        return rsi.fillna(50.0)  # NaN ê°’ì„ 50ìœ¼ë¡œ ëŒ€ì²´

    def calculate_bollinger_bands(self, df: pd.DataFrame) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°"""
        # ë°ì´í„° íƒ€ì…ì„ floatìœ¼ë¡œ ë³€í™˜
        close_prices = df['close'].astype(float)
        
        # ì¤‘ê°„ ë°´ë“œ (20ì¼ ì´ë™í‰ê· )
        middle = close_prices.rolling(window=self.bb_period).mean()
        
        # í‘œì¤€í¸ì°¨ ê³„ì‚°
        std = close_prices.rolling(window=self.bb_period).std()
        
        # ìƒë‹¨ê³¼ í•˜ë‹¨ ë°´ë“œ
        upper = middle + (std * float(self.bb_std))
        lower = middle - (std * float(self.bb_std))
        
        # NaN ê°’ ì²˜ë¦¬
        middle = middle.fillna(close_prices)
        upper = upper.fillna(close_prices * 1.02)  # NaNì¸ ê²½ìš° í˜„ì¬ê°€ + 2%
        lower = lower.fillna(close_prices * 0.98)  # NaNì¸ ê²½ìš° í˜„ì¬ê°€ - 2%
        
        return lower, middle, upper

def get_cache_key(ticker: str, start_date: str, end_date: str) -> str:
    """ìºì‹œ í‚¤ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
    key = f"{ticker}_{start_date}_{end_date}_minute5"
    cache_key = hashlib.md5(key.encode()).hexdigest()
    logging.debug(f"ìºì‹œ í‚¤ ìƒì„±: {key} -> {cache_key}")
    return cache_key

def get_cached_data(cache_key: str, cache_dir: str = CACHE_DIR) -> Optional[pd.DataFrame]:
    """ìºì‹œëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê°œì„ ëœ ë²„ì „)"""
    try:
        cache_file = os.path.join(cache_dir, f"{cache_key}.pkl")
        logging.debug(f"ìºì‹œ íŒŒì¼ í™•ì¸: {cache_file}")
        
        if os.path.exists(cache_file):
            # ìºì‹œ íŒŒì¼ì˜ ìˆ˜ì • ì‹œê°„ í™•ì¸
            cache_mtime = datetime.fromtimestamp(os.path.getmtime(cache_file))
            cache_age = datetime.now() - cache_mtime
            
            # ìºì‹œê°€ 24ì‹œê°„ ì´ìƒ ì§€ë‚¬ìœ¼ë©´ ë¬´íš¨í™”
            if cache_age.total_seconds() > 86400:  # 24ì‹œê°„
                logging.info(f"ìºì‹œ íŒŒì¼ ë§Œë£Œ: {cache_file}")
                os.remove(cache_file)  # ë§Œë£Œëœ ìºì‹œ íŒŒì¼ ì‚­ì œ
                return None
                
            with open(cache_file, "rb") as f:
                data = pickle.load(f)
                
            if isinstance(data, pd.DataFrame) and not data.empty:
                required_columns = ['open', 'high', 'low', 'close', 'volume']
                if all(col in data.columns for col in required_columns):
                    logging.info(f"ìºì‹œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {cache_file} (í–‰: {len(data)})")
                    return data
                    
        else:
            logging.debug(f"ìºì‹œ íŒŒì¼ ì—†ìŒ: {cache_file}")
                    
    except Exception as e:
        logging.warning(f"ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    return None

def save_to_cache(data: pd.DataFrame, cache_key: str, cache_dir: str = CACHE_DIR) -> None:
    """ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥ (ê°œì„ ëœ ë²„ì „)"""
    try:
        if data is None or data.empty:
            logging.warning("ë¹ˆ ë°ì´í„°ëŠ” ìºì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return
            
        cache_file = os.path.join(cache_dir, f"{cache_key}.pkl")
        logging.debug(f"ìºì‹œ ì €ì¥ ì‹œë„: {cache_file}")
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(cache_dir, exist_ok=True)
        
        with open(cache_file, "wb") as f:
            pickle.dump(data, f)
        logging.info(f"ìºì‹œ ì €ì¥ ì„±ê³µ: {cache_file} (í–‰: {len(data)})")
        
    except Exception as e:
        logging.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def fetch_ohlcv(ticker: str, start_date: str, end_date: str, interval: str = "minute5", allow_partial: bool = True) -> pd.DataFrame:
    """OHLCV ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    cache_key = get_cache_key(ticker, start_date, end_date)
    cached_data = get_cached_data(cache_key)
    
    if cached_data is not None:
        print(f"{ticker}: ìºì‹œëœ ë°ì´í„° ì‚¬ìš©")
        print(f"ë°ì´í„° ê¸°ê°„: {cached_data.index[0].strftime('%Y-%m-%d')} ~ {cached_data.index[-1].strftime('%Y-%m-%d')}")
        return cached_data

    print(f"\n{ticker}: ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print(f"ìš”ì²­ ê¸°ê°„: {start_date} ~ {end_date}")
    
    # ë‚ ì§œ ë³€í™˜
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    
    all_data = []
    current_dt = end_dt
    total_days = (end_dt - start_dt).days
    days_processed = 0
    last_progress = -1
    last_update_time = datetime.now()
    retries = 0
    max_retries = 3
    no_progress_timeout = 300  # 5ë¶„ ë™ì•ˆ ì§„í–‰ì´ ì—†ìœ¼ë©´ íƒ€ì„ì•„ì›ƒ
    collection_status = "ì™„ë£Œ"  # ìˆ˜ì§‘ ìƒíƒœ ì¶”ì 
    
    def print_progress(force=False):
        nonlocal last_progress, last_update_time
        current_time = datetime.now()
        elapsed = (current_time - last_update_time).total_seconds()
        progress = min(100, int((days_processed / total_days) * 100))
        
        if progress != last_progress or force:
            time_str = current_time.strftime("%H:%M:%S")
            if elapsed > 60:
                status = f"(ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {int(elapsed)}ì´ˆ ì „)"
            else:
                status = "(ì§„í–‰ì¤‘)"
            print(f"\r{ticker} ì§„í–‰ë¥ : {progress}% - {time_str} {status}", end='')
            last_progress = progress
            if progress != last_progress:
                last_update_time = current_time
            
        return progress, elapsed
    
    while current_dt >= start_dt:
        try:
            df = safe_request_with_retry(
                lambda: pyupbit.get_ohlcv(ticker=ticker, interval=interval, count=200, to=current_dt),
                max_retries=3,
                delay=1.0
            )
            
            if df is None or df.empty:
                collection_status = "ë°ì´í„° ì—†ìŒ"
                logger.info(f"{ticker}: ë” ì´ìƒì˜ ê³¼ê±° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í˜„ì¬: {current_dt.strftime('%Y-%m-%d')})")
                break
                
            all_data.append(df)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            current_dt = df.index[0]
            days_processed = (end_dt - current_dt).days
            progress, elapsed = print_progress()
            
            # íƒ€ì„ì•„ì›ƒ ì²´í¬
            if elapsed > no_progress_timeout:
                collection_status = "ì‹œê°„ ì´ˆê³¼"
                logger.warning(f"{ticker}: {no_progress_timeout}ì´ˆ ë™ì•ˆ ì§„í–‰ì´ ì—†ì–´ ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break
            
            if progress >= 100:
                break
                
            time.sleep(0.1)
            retries = 0
            
        except Exception as e:
            retries += 1
            if retries >= max_retries:
                collection_status = "ì˜¤ë¥˜"
                logger.error(f"{ticker} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {str(e)}")
                break
            logger.warning(f"{ticker} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ (ì¬ì‹œë„ {retries}/{max_retries}): {str(e)}")
            time.sleep(retries * 2)
    
    # ë§ˆì§€ë§‰ ì§„í–‰ë¥  ê°•ì œ ì¶œë ¥
    print_progress(force=True)
    print()  # ì¤„ë°”ê¿ˆ
    
    if not all_data:
        logger.warning(f"{ticker}: ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    
    try:
        final_df = pd.concat(all_data).sort_index()
        final_df = final_df[~final_df.index.duplicated(keep='first')]
        
        if not final_df.empty:
            actual_start = final_df.index[0].strftime('%Y-%m-%d')
            actual_end = final_df.index[-1].strftime('%Y-%m-%d')
            completeness = (len(final_df) / (total_days * 288)) * 100  # 5ë¶„ ë´‰ ê¸°ì¤€ í•˜ë£¨ 288ê°œ
            
            print(f"\n{ticker} ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼:")
            print(f"- ìƒíƒœ: {collection_status}")
            print(f"- ì‹¤ì œ ìˆ˜ì§‘ ê¸°ê°„: {actual_start} ~ {actual_end}")
            print(f"- ë°ì´í„° ì™„ì„±ë„: {completeness:.1f}%")
            print(f"- ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(final_df):,}ê°œ")
            
            if collection_status != "ì™„ë£Œ" and not allow_partial:
                logger.warning(f"{ticker}: ë¶€ë¶„ ë°ì´í„° ìˆ˜ì§‘ë¨ (allow_partial=False)")
                return pd.DataFrame()
            
            save_to_cache(final_df, cache_key)
            logger.info(f"{ticker}: ë°ì´í„° ì €ì¥ ì™„ë£Œ (í–‰: {len(final_df)})")
            
            return final_df
    except Exception as e:
        logger.error(f"{ticker} ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

def parallel_fetch_data(args) -> tuple:
    """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ (ìºì‹œ í™œìš©)"""
    ticker, start_date, end_date = args
    
    # í”„ë¡œì„¸ìŠ¤ë³„ ë¡œê±° ì„¤ì •
    process_logger = logging.getLogger(f'Process-{ticker}')
    process_logger.setLevel(logging.DEBUG)
    
    if not process_logger.handlers:
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.DEBUG)
        formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
        console_handler.setFormatter(formatter)
        process_logger.addHandler(console_handler)
    
    try:
        process_logger.info(f"{ticker}: ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        # ìºì‹œ í‚¤ ìƒì„± ë° í™•ì¸
        cache_key = get_cache_key(ticker, start_date, end_date)
        cached_data = get_cached_data(cache_key)
        
        if cached_data is not None:
            process_logger.info(f"{ticker}: ìºì‹œëœ ë°ì´í„° ì‚¬ìš© (í–‰: {len(cached_data)})")
            return ticker, cached_data
            
        process_logger.info(f"{ticker}: ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        df = fetch_ohlcv(ticker, start_date, end_date, allow_partial=True)
        
        if df.empty:
            process_logger.warning(f"{ticker}: ë°ì´í„° ì—†ìŒ")
            return ticker, pd.DataFrame()
            
        # ìƒˆë¡œ ë°›ì€ ë°ì´í„° ìºì‹œì— ì €ì¥
        save_to_cache(df, cache_key)
        process_logger.info(f"{ticker}: ìƒˆë¡œìš´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ (í–‰: {len(df)})")
        return ticker, df
        
    except Exception as e:
        process_logger.error(f"{ticker} ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return ticker, pd.DataFrame()

def backtest_strategy(strategy, df):
    """ì „ëµ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    trades = []
    holding = False
    entry_price = None
    entry_time = None
    position_size = 1.0
    
    # DataFrameì„ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©
    df = df.copy()
    # ìˆ«ìí˜• ì»¬ëŸ¼ì„ float íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    for col in ['open', 'high', 'low', 'close', 'volume']:
        df[col] = df[col].astype(float)
    
    for i in range(len(df)):
        current_time = df.index[i]
        current_price = float(df['close'].iloc[i])
        
        if not holding:
            # ì§„ì… í‰ê°€
            if i >= max(strategy.rsi_period, strategy.bb_period) + 10:
                window_df = df.iloc[max(0, i-100):i+1].copy()
                try:
                    if strategy.evaluate_entry(window_df):
                        holding = True
                        entry_price = current_price
                        entry_time = current_time
                        strategy.last_trade_time = current_time
                except Exception as e:
                    logging.error(f"ì§„ì… í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    continue
        else:
            # ë³´ìœ  ì‹œê°„ ê³„ì‚°
            hold_time = (current_time - entry_time).total_seconds() / 3600
            
            # í‡´ì¶œ í‰ê°€
            window_df = df.iloc[max(0, i-100):i+1].copy()
            try:
                exit_flag, reason = strategy.evaluate_exit(window_df, entry_price, hold_time)
                
                if exit_flag:
                    profit_ratio = float(current_price) / float(entry_price) - 1
                    trade_result = {
                        "entry": entry_time,
                        "exit": current_time,
                        "pnl": float(profit_ratio * 100 * position_size),
                        "reason": reason,
                        "size": float(position_size)
                    }
                    trades.append(trade_result)
                    
                    holding = False
                    entry_price = None
                    entry_time = None
                    position_size = 1.0
            except Exception as e:
                logging.error(f"í‡´ì¶œ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue

    return pd.DataFrame(trades)

def analyze_results(df_trades: pd.DataFrame) -> Dict:
    if df_trades.empty:
        return {
            "trades": 0,
            "win_rate": 0,
            "total_return": 0,
            "sharpe": 0
        }
    wins = df_trades[df_trades['pnl'] > 0]
    pnl_std = df_trades['pnl'].std()
    return {
        "trades": len(df_trades),
        "win_rate": len(wins) / len(df_trades) * 100,
        "total_return": df_trades['pnl'].sum(),
        "sharpe": np.sqrt(252) * df_trades['pnl'].mean() / pnl_std if pnl_std != 0 else 0
    }

def print_trade_summary(ticker: str, result: Dict) -> None:
    """ê±°ë˜ ê²°ê³¼ ìš”ì•½ì„ ì˜ˆì˜ê²Œ ì¶œë ¥"""
    print("\n" + "="*50)
    print(f"ğŸª™ {ticker} ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("-"*50)
    print(f"ğŸ“Š ì´ ê±°ë˜ íšŸìˆ˜: {result['trades']}íšŒ")
    print(f"âœ¨ ìŠ¹ë¥ : {result['win_rate']:.2f}%")
    
    # ìˆ˜ìµë¥ ì— ë”°ë¥¸ ì´ëª¨ì§€ ì„ íƒ
    if result['total_return'] > 0:
        return_emoji = "ğŸ”¥"
    elif result['total_return'] < 0:
        return_emoji = "ğŸ“‰"
    else:
        return_emoji = "â–"
    print(f"{return_emoji} ì´ ìˆ˜ìµë¥ : {result['total_return']:.2f}%")
    
    # ìƒ¤í”„ë¹„ìœ¨ì— ë”°ë¥¸ ì´ëª¨ì§€ ì„ íƒ
    if result['sharpe'] > 1:
        sharpe_emoji = "â­"
    elif result['sharpe'] > 0:
        sharpe_emoji = "âœ…"
    else:
        sharpe_emoji = "âš ï¸"
    print(f"{sharpe_emoji} ìƒ¤í”„ë¹„ìœ¨: {result['sharpe']:.2f}")
    print("="*50)

def run_multi_coin_backtest(tickers: List[str], start_date: str, end_date: str, num_simulations: int = 1):
    """ë©€í‹° ì½”ì¸ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê°œì„ ëœ ë²„ì „)"""
    # ë°ì´í„° ë¡œë”© ì§„í–‰ë¥  í‘œì‹œ ì¶”ê°€
    print("\në°ì´í„° ë¡œë”© ì‹œì‘...")
    total_tickers = len(tickers)
    
    # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ í’€ ìƒì„±
    num_processes = min(mp.cpu_count(), total_tickers)
    fetch_args = [(ticker, start_date, end_date) for ticker in tickers]
    
    all_data = {}
    with mp.Pool(num_processes) as pool:
        for i, (ticker, df) in enumerate(pool.imap_unordered(parallel_fetch_data, fetch_args), 1):
            print(f"\rë°ì´í„° ë¡œë”© ì§„í–‰ë¥ : {i}/{total_tickers} ({i/total_tickers*100:.1f}%)", end="")
            if not df.empty:
                all_data[ticker] = df
    
    print("\në°ì´í„° ë¡œë”© ì™„ë£Œ!")
    print(f"ë¡œë“œëœ ì½”ì¸ ìˆ˜: {len(all_data)}/{total_tickers}")
    
    # ì´í›„ ì½”ë“œëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€
    all_results = []
    
    print("ğŸ“ˆ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“… ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"ğŸ¯ ëŒ€ìƒ ì½”ì¸: {', '.join(tickers)}")
    print(f"ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜: {num_simulations}")

    for sim in range(num_simulations):
        print(f"--- ì‹œë®¬ë ˆì´ì…˜ {sim + 1}/{num_simulations} ---")
        summary = {}
        total_tickers = len(tickers)

        for idx, ticker in enumerate(tickers, 1):
            try:
                print(f"â³ ì§„í–‰ë¥ : {idx}/{total_tickers} - {ticker} ë¶„ì„ ì¤‘ (ì‹œë®¬ë ˆì´ì…˜ {sim + 1})...")
                
                df = fetch_ohlcv(ticker, start_date, end_date)
                if df.empty:
                    logging.warning(f"{ticker}: ë°ì´í„° ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue
                
                # ì½”ì¸ë³„ë¡œ ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜ë§ˆë‹¤ ìƒˆ íŒŒë¼ë¯¸í„° ìƒì„±)
                strategy = RSIReversalStrategy(ticker)
                # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œ strategy ê°ì²´ ì „ë‹¬ í™•ì¸
                trades = backtest_strategy(strategy, df.copy()) # ì›ë³¸ ë°ì´í„° ë³´ì¡´ ìœ„í•´ ë³µì‚¬ë³¸ ì „ë‹¬
                result = analyze_results(trades)
                summary[ticker] = result
                
                # ì²« ì‹œë®¬ë ˆì´ì…˜ì—ì„œë§Œ ìƒì„¸ ë¡œê·¸ ì €ì¥ (ì„ íƒì )
                if sim == 0 and not trades.empty:
                     trades_filename = os.path.join(LOG_DIR, f"trades_{ticker}_{start_date}_{end_date}_sim{sim+1}.csv")
                     trades.to_csv(trades_filename)
                     print(f"ğŸ“„ {ticker} ê±°ë˜ ë‚´ì—­ ì €ì¥ë¨: {trades_filename}")

                print_trade_summary(ticker, result)
                
            except Exception as e:
                logging.error(f"{ticker} ë°±í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì‹œë®¬ë ˆì´ì…˜ {sim + 1}): {str(e)}")
                summary[ticker] = {
                    "trades": 0,
                    "win_rate": 0,
                    "total_return": 0,
                    "sharpe": 0
                }
        
        result_df = pd.DataFrame(summary).T
        result_df['simulation'] = sim + 1
        all_results.append(result_df)

    # ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì§‘ê³„
    final_results_df = pd.concat(all_results)

    print("ğŸ‰ ì „ì²´ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    if not final_results_df.empty:
        # ì‹œë®¬ë ˆì´ì…˜ ì „ì²´ ê²°ê³¼ ìš”ì•½
        print("=== ğŸ“Š ì „ì²´ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìš”ì•½ (í‰ê· ê°’) ===")
        # numeric_only=True ì¶”ê°€í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
        mean_results = final_results_df.groupby(final_results_df.index).mean(numeric_only=True)
        print(f"ğŸ“ˆ í‰ê·  ìŠ¹ë¥ : {mean_results['win_rate'].mean():.2f}%")
        print(f"ğŸ’° í‰ê·  ìˆ˜ìµë¥ : {mean_results['total_return'].mean():.2f}%")
        print(f"ğŸ“Š í‰ê·  ìƒ¤í”„ë¹„ìœ¨: {mean_results['sharpe'].mean():.2f}")
        print(f"ğŸ”„ í‰ê·  ê±°ë˜íšŸìˆ˜ (ì½”ì¸ë‹¹): {mean_results['trades'].mean():.1f}íšŒ")
        
        # ê²°ê³¼ ì €ì¥
        results_filename = os.path.join(LOG_DIR, f"rsi_reversal_multi_result_simulations_{start_date}_{end_date}.csv")
        final_results_df.to_csv(results_filename)
        print(f"\nğŸ’¾ ì „ì²´ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_filename}")

        # ìµœê³ /ìµœì € ì„±ê³¼ ì½”ì¸ (í‰ê·  ê¸°ì¤€)
        best_coin_avg = mean_results['total_return'].idxmax()
        worst_coin_avg = mean_results['total_return'].idxmin()
        print(f"\nğŸ† ìµœê³  ì„±ê³¼ (í‰ê· ): {best_coin_avg} ({mean_results.loc[best_coin_avg, 'total_return']:.2f}%)")
        print(f"\nâš ï¸ ìµœì € ì„±ê³¼ (í‰ê· ): {worst_coin_avg} ({mean_results.loc[worst_coin_avg, 'total_return']:.2f}%)")
    else:
        print("\nê²°ê³¼ ë°ì´í„°ê°€ ì—†ì–´ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return final_results_df # ìµœì¢… ê²°ê³¼ ë°˜í™˜

def analyze_market_condition(df: pd.DataFrame) -> dict:
    """ì‹œì¥ ìƒíƒœ ë¶„ì„"""
    # ë³€ë™ì„± ê³„ì‚°
    returns = df['close'].pct_change()
    volatility = returns.std() * np.sqrt(252)  # ì—°ê°„í™”ëœ ë³€ë™ì„±
    
    # ì¶”ì„¸ ê°•ë„ ê³„ì‚°
    ma_short = df['close'].rolling(window=20).mean()  # 20ì¼ ì´ë™í‰ê· 
    ma_long = df['close'].rolling(window=60).mean()   # 60ì¼ ì´ë™í‰ê· 
    trend_strength = (ma_short.iloc[-1] / ma_long.iloc[-1] - 1) * 100
    
    # ê±°ë˜ëŸ‰ íŠ¹ì„±
    volume_ma = df['volume'].rolling(window=20).mean()
    volume_ratio = df['volume'].iloc[-1] / volume_ma.iloc[-1]
    
    # ì‹œì¥ ìƒíƒœ íŒë‹¨
    market_state = "íš¡ë³´ì¥"
    if trend_strength > 1.5 and volatility < 0.5:
        market_state = "ê°•ì„¸ì¥"
    elif trend_strength < -1.5 and volatility > 0.8:
        market_state = "ì•½ì„¸ì¥"
    elif volatility > 1.0:
        market_state = "ê³ ë³€ë™ì„±"
    
    return {
        "volatility": volatility,
        "trend_strength": trend_strength,
        "volume_ratio": volume_ratio,
        "market_state": market_state
    }

def run_walk_forward_backtest(tickers: List[str], start_date: str, end_date: str,
                          lookback_days: int, test_days: int, num_simulations: int = 1):
    """Walk-Forward ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë©”íƒ€ë°ì´í„° ë¶„ì„ ì¶”ê°€)"""
    print("\nğŸ“ˆ Walk-Forward ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“… ì „ì²´ ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"ğŸ—“ï¸ í•™ìŠµ ê¸°ê°„: {lookback_days}ì¼, í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_days}ì¼")
    print(f"ğŸ¯ ëŒ€ìƒ ì½”ì¸: {', '.join(tickers)}")
    print(f"ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜ (ì°½ë³„): {num_simulations}")
    
    all_results = []
    window_results = []
    
    print("\në°ì´í„° ë¡œë”© ì¤‘...")
    data_dict = {}
    for ticker in tickers:
        print(f"\n{ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = fetch_ohlcv(ticker, start_date, end_date)
        if len(df) > 0:
            data_dict[ticker] = df
    
    print(f"\në°ì´í„° ë¡œë”© ì™„ë£Œ. (ë¡œë“œëœ ì½”ì¸: {len(data_dict)}ê°œ)\n")
    
    # í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì„¤ì •
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    test_start = end_dt - timedelta(days=test_days)
    
    window_num = 1
    print(f"--- Window {window_num} --- ({test_start.strftime('%Y-%m-%d')} ~ {end_dt.strftime('%Y-%m-%d')}) ---\n")
    
    for ticker in tickers:
        if ticker not in data_dict:
            continue
            
        df = data_dict[ticker]
        if len(df) == 0:
            continue
            
        # ì‹œì¥ ìƒíƒœ ë¶„ì„
        market_condition = analyze_market_condition(df)
        print(f"\n{ticker} ì‹œì¥ ìƒíƒœ:")
        print(f"- ë³€ë™ì„±: {market_condition['volatility']:.2f}")
        print(f"- ì¶”ì„¸ ê°•ë„: {market_condition['trend_strength']:.2f}")
        print(f"- ê±°ë˜ëŸ‰ ë¹„ìœ¨: {market_condition['volume_ratio']:.2f}")
        print(f"- ì‹œì¥ êµ­ë©´: {market_condition['market_state']}")
            
        print(f"\nâ³ {ticker} (Window {window_num}) ë¶„ì„ ì¤‘ ({num_simulations}íšŒ ì‹œë®¬ë ˆì´ì…˜)...")
        
        window_trades = []
        sim_results = []
        for sim in range(num_simulations):
            try:
                strategy = RSIReversalStrategy(ticker, is_backtest=True)
                test_data = df[df.index >= test_start]
                trades_df = backtest_strategy(strategy, test_data)
                
                if not trades_df.empty:
                    trades_df['simulation'] = sim + 1
                    window_trades.append(trades_df)
                    
                    # ì‹œë®¬ë ˆì´ì…˜ë³„ ê²°ê³¼ ì €ì¥
                    sim_result = analyze_results(trades_df)
                    sim_result.update({
                        'simulation': sim + 1,
                        'market_condition': market_condition['market_state']
                    })
                    sim_results.append(sim_result)
                    
            except Exception as e:
                logging.error(f"{ticker} (Window {window_num}, Sim {sim+1}) ë°±í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë¶„ì„
        if sim_results:
            sim_results_df = pd.DataFrame(sim_results)
            
            # í†µê³„ ë¶„ì„
            stats = {
                'avg_return': sim_results_df['total_return'].mean(),
                'std_return': sim_results_df['total_return'].std(),
                'worst_return': sim_results_df['total_return'].min(),
                'best_return': sim_results_df['total_return'].max(),
                'avg_trades': sim_results_df['trades'].mean(),
                'avg_win_rate': sim_results_df['win_rate'].mean(),
                'market_state': market_condition['market_state']
            }
            
            print("\n==================================================")
            print(f" {ticker} (Window {window_num}) í†µê³„ ë¶„ì„")
            print("--------------------------------------------------")
            print(f"ğŸ“Š í‰ê·  ê±°ë˜ íšŸìˆ˜: {stats['avg_trades']:.1f}íšŒ")
            print(f"âœ¨ í‰ê·  ìŠ¹ë¥ : {stats['avg_win_rate']:.2f}%")
            print(f"ğŸ“ˆ í‰ê·  ìˆ˜ìµë¥ : {stats['avg_return']:.2f}%")
            print(f"ğŸ“Š ìˆ˜ìµë¥  í‘œì¤€í¸ì°¨: {stats['std_return']:.2f}%")
            print(f"â­ ìµœê³  ìˆ˜ìµë¥ : {stats['best_return']:.2f}%")
            print(f"âš ï¸ ìµœì € ìˆ˜ìµë¥ : {stats['worst_return']:.2f}%")
            print(f"ğŸŒ ì‹œì¥ ìƒíƒœ: {stats['market_state']}")
            print("==================================================\n")
            
            stats.update({
                'ticker': ticker,
                'window': window_num
            })
            window_results.append(stats)
            
    # ê²°ê³¼ ì €ì¥
    results_df = pd.DataFrame(window_results)
    save_path = os.path.join(LOG_DIR, f"rsi_reversal_detailed_results_{start_date}_{end_date}.csv")
    results_df.to_csv(save_path, index=False)
    print(f"\nğŸ’¾ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}")
    
    # ì‹œì¥ ìƒíƒœë³„ ì„±ê³¼ ë¶„ì„
    if not results_df.empty:
        print("\n=== ğŸ“Š ì‹œì¥ ìƒíƒœë³„ í‰ê·  ì„±ê³¼ ===")
        market_stats = results_df.groupby('market_state').agg({
            'avg_return': 'mean',
            'worst_return': 'min',
            'avg_win_rate': 'mean',
            'avg_trades': 'mean'
        }).round(2)
        print(market_stats)
    
    return results_df

if __name__ == "__main__":
    logger.info("===== í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹œì‘ =====")
    try:
        # BTCë¥¼ ì²«ë²ˆì§¸ë¡œ, DOGEë¥¼ ë‘ë²ˆì§¸ë¡œ ìˆœì„œ ë³€ê²½
        altcoins = ["KRW-BTC", "KRW-DOGE", "KRW-XRP", "KRW-SOL", "KRW-SAND", "KRW-ARB"]
        
        # 3ë…„ì¹˜ ë°ì´í„° ë¡œë“œ (ARBëŠ” ìƒì¥ì¼ ì´í›„ë¶€í„°)
        current_date = datetime.now()
        three_years_ago = (current_date - timedelta(days=365*3)).strftime("%Y-%m-%d")
        current_date_str = current_date.strftime("%Y-%m-%d")
        
        print("\n3ë…„ì¹˜ ë°ì´í„° ë¡œë“œ ì¤‘...")
        all_data = {}
        for ticker in altcoins:
            print(f"{ticker} ë°ì´í„° ë¡œë“œ ì¤‘...")
            # ARBì˜ ê²½ìš° ë” ì§§ì€ ê¸°ê°„ ì„¤ì • (2023ë…„ 3ì›” ìƒì¥)
            start_date = "2023-03-01" if ticker == "KRW-ARB" else three_years_ago
            df = fetch_ohlcv(ticker, start_date, current_date_str, allow_partial=True)  # ë¶€ë¶„ ë°ì´í„° í—ˆìš©
            if not df.empty:
                all_data[ticker] = df
                print(f"{ticker}: {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ë¡œë“œë¨")
            else:
                logger.warning(f"{ticker}: ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        
        # ì—¬ëŸ¬ ë²ˆì˜ ëœë¤ ìœˆë„ìš° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        num_windows = 5  # ëœë¤ ìœˆë„ìš° íšŸìˆ˜
        all_window_results = []
        
        for window in range(num_windows):
            print(f"\n=== ëœë¤ ìœˆë„ìš° í…ŒìŠ¤íŠ¸ {window + 1}/{num_windows} ===")
            
            # ëœë¤í•œ 120ì¼ êµ¬ê°„ ì„ íƒ (ìµœê·¼ 2ë…„ ë‚´ì—ì„œ)
            random_start_days = random.randint(120, 730)  # ìµœëŒ€ 2ë…„ ì „ê¹Œì§€
            end_date = (current_date - timedelta(days=random_start_days)).strftime("%Y-%m-%d")
            start_date = (current_date - timedelta(days=random_start_days + 120)).strftime("%Y-%m-%d")
            
            print(f"\nì„ íƒëœ ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„:")
            print(f"ì‹œì‘ì¼: {start_date}")
            print(f"ì¢…ë£Œì¼: {end_date}")
            print(f"ê¸°ê°„ ê¸¸ì´: 120ì¼\n")
            
            # ì„ íƒëœ ê¸°ê°„ì˜ ë°ì´í„°ë§Œ í•„í„°ë§
            filtered_data = {}
            for ticker, df in all_data.items():
                mask = (df.index >= start_date) & (df.index <= end_date)
                filtered_df = df[mask].copy()
                if not filtered_df.empty:
                    filtered_data[ticker] = filtered_df
                    print(f"{ticker}: ì„ íƒëœ ê¸°ê°„ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ - {len(filtered_df)}")
            
            lookback = 60
            test = 30
            num_simulations = 5

            try:
                # Walk-Forward ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                window_results = run_walk_forward_backtest(
                    list(filtered_data.keys()), start_date, end_date, lookback, test, num_simulations
                )
                all_window_results.append(window_results)
            except Exception as e:
                logging.error(f"ìœˆë„ìš° {window + 1} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
        
        # ì „ì²´ ê²°ê³¼ í†µí•© ë¶„ì„
        if all_window_results:
            combined_results = pd.concat(all_window_results, ignore_index=True)
            
            print("\n=== ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í†µê³„ ===")
            print("\n1. ì „ì²´ í‰ê·  ì„±ê³¼:")
            print(f"í‰ê·  ìˆ˜ìµë¥ : {combined_results['avg_return'].mean():.2f}% (í‘œì¤€í¸ì°¨: {combined_results['std_return'].mean():.2f}%)")
            print(f"í‰ê·  ìŠ¹ë¥ : {combined_results['avg_win_rate'].mean():.2f}%")
            print(f"í‰ê·  ê±°ë˜ íšŸìˆ˜: {combined_results['avg_trades'].mean():.1f}")
            
            print("\n2. Worst-Case ì‹œë‚˜ë¦¬ì˜¤:")
            print(f"ìµœì € ìˆ˜ìµë¥ : {combined_results['worst_return'].min():.2f}%")
            print(f"ìµœì € ìŠ¹ë¥ : {combined_results['avg_win_rate'].min():.2f}%")
            
            print("\n3. ì‹œì¥ ìƒíƒœë³„ ì„±ê³¼:")
            market_performance = combined_results.groupby('market_state').agg({
                'avg_return': ['mean', 'std'],
                'worst_return': 'min',
                'avg_win_rate': 'mean',
                'avg_trades': 'mean'
            }).round(2)
            print(market_performance)
            
            # ìµœì¢… ê²°ê³¼ ì €ì¥
            final_save_path = os.path.join(LOG_DIR, f"rsi_reversal_complete_analysis_{current_date_str}.csv")
            combined_results.to_csv(final_save_path, index=False)
            print(f"\nğŸ’¾ ìµœì¢… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {final_save_path}")

        logger.info("===== ëª¨ë“  ìœˆë„ìš° í…ŒìŠ¤íŠ¸ ë° ë¶„ì„ ì™„ë£Œ ====")
        
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        import traceback
        traceback.print_exc()
    finally:
        logger.info("===== í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¢…ë£Œ =====") # ì¢…ë£Œ ë¡œê·¸ ì¶”ê°€
        logging.shutdown() # ë¡œê¹… ì‹œìŠ¤í…œ ì¢…ë£Œ (ë²„í¼ í”ŒëŸ¬ì‹œ)
